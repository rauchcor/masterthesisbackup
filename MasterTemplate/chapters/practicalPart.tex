%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Practical Part}\label{chap:practicalPart}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapterstart

The practical part of this work consists of three parts: the use case, a risk assessment and an example solution based on what was learned from the risk assessment. In the first part a use case is described. The use case tries to picture a typical scenario that requires thoughtful consideration of authentication and authorization technologies depending on the requirements of the use case. Based on the use case a small risk assessment is done. This risk assessment should help to choose an appropriate level of assurance for identity proofing, authentication and federation. Based on this risk assessment a small application is implemented. The procedure of conducting a risk assessment first should help developers to choose appropriate authentication and authorization methods for a particular use case.  

\section{Use Case}
\label{usecase}
This use case is based on an similar use case of the company "ACP Business Applications" where I am currently employed. This should allow the reader to get a better understanding of the circumstances that led to the design of a federated authentication solution. 

The use case features a medium to large company with up to 1000 employees. The mission of the company is to provide a network and analyzing toolset which allows the customer of the product suite to improve security within his network and keep an overview of potential security risks. Previously the customers received monthly reports about their current state of the network. Each of the products and tools resulted in a separate report which was sent via e-mail. To modernize the approach, the reports should be replaced by a modern single-page application that could be accessed by customers and by employees for administrative reasons. In this example, we call the solution 'Security Assessment Portal.' The Security Assessment Portal should give the customers an overview of current products and the performance of the network. An example of the toolset could be E-Mail-Filtering. The example will be focused on an E-Mail-Filtering-Report and the data which is exposed via the report. It is very important to have a good overview of the data that is used within the application in order to establish appropriate security controls. The Email-Filtering-Report will display a chart per domain. The chart includes data about the amount of e-mails which were blocked, received or carried a virus. 

The company already has a particular set of internal applications that are used by the employees within the company network. The company internally uses active directory for authorization on local machines. All applications until now are accessible within the companies network and are using windows authentication. The application should be accessible by employees as well as customers whereas customers should not receive access to the company network. The data of the customers is sensitive and therefore worth protecting. However it should be kept in mind that because of the sensitive data, certain customer do not want to authenticate with an external provider. The application should be hosted within the company and a solution for customers to access the application from outside is needed. The company needs an authentication solution that meets all the outlined requirements while balancing usability and security. 

The description gives an overview of the company and the expectations for the new application. This leads to the following requirements for the system architecture:

\begin{itemize}
	\item Access from outside the company network is enabled
	\item Application is secured with accounts
	\item Accounts should be managed within the company
	\item Only authenticated users have access to secure contents
	\item Single sign-on for convenience
	\item API for data access
	\item Data can be hosted within the company
	\item The application should be a light weighted Angular solution
\end{itemize} 

The application and its requirements are taken into account in the risk assessment conducted in the next section \ref{riskassessment} Risk Assessment. The risk assessment should lead to an better understanding which security measurements are needed for this use case. 

\section{Risk Assessment}
\label{riskassessment}
Risk Assessment is one of the essential elements when it comes to managing risks of an organization. The aim of risk assessment is it to identify, estimate, and prioritize risk to operations, assets, individuals, other organizations and use of the information system. The main task of a risk assessment is to help making decisions on how to respond to certain risk. The steps to a risk assessment are identifying potential threats, internal and external vulnerabilities, the impact to organizations given the potential for threats exploiting vulnerabilities and the likelihood of that harm to occur. There are three tiers according to (\cite{NIST:2012:GCRA}, p.1) in risk management:

\begin{itemize}
	\item Tier 1 - organizational level
	\item Tier 2 - mission/business process level
	\item Tier 3 - information system level
\end{itemize}

The first two tiers are focusing on risks related to organizational governance and management activities, mission/business processes, enterprise architecture or the funding of information security programs. The third tier focuses more on how to implement a risk management framework successfully [cf. (\cite{NIST:2012:GCRA}, p.1)]. 

The result of the risk assessment should state which assurance levels are appropriate.
The available assurance levels are identity proofing assurance level, authentication assurance level and the federate assurance level. Identity proofing assurance level describes the robustness of the process to determine the identity of an individual and should help to avoid identity proofing errors. To determine the robustness of the authentication process and the binding of an authenticator and a specific individual's identifier the authentication assurance level is used. Furthermore choosing an appropriate authentication assurance level should help to avoid authentication errors. The last one of the assurance level is the federated assurance level which is optional since not all identity systems need a federated identity solution. The federated assurance level determines the robustness of the assertion protocol the federation uses to communicate authentication and attribute information and should help to avoid federation errors. All of the assurance levels a described in more detail in the sections \ref{identityProofing} Identity Proofing, \ref{authentication} Authentication and  \ref{assertion} Assertion [cf. (\cite{NIST:2017:DIG}, p.19)]. 

To determine assurance levels one needs to identify the potential risk and which measures exist to minimize the impact of those risks. Two factors are crucial for this task. The first factor is the potential harm or impact, and the second the likelihood of such harm or impact. \cite{Bolton:2003:EAuth}, pp.3 splits harm and impact into these categories:

\begin{itemize}
	\item Inconvenience, distress, or damage to standing or reputation
	\item Financial loss or agency liability
	\item Harm to agency programs or public interests
	\item Unauthorized release of sensitive information
	\item Personal safety
	\item Civil or criminal violations
\end{itemize}

Assurance levels are determined by assessing the potential impact of these categories. \cite{NIST:2004:FIOPS} defines three levels of potential impact concerning security objectives confidentiality, integrity, and availability. Those levels of potential impacts can affect in case of a security breach either the organization or individuals. The levels of impact defined by \cite{NIST:2004:FIOPS} are:

\begin{itemize}
	\item Low
	\item Moderate
	\item High
\end{itemize}


If the level is low the loss of confidentiality, integrity or availability has a limited effect. This can mean for example minor damage to organizational assets, short-term inconvenience, short-term distress, short-term embarrassment, limited reveal of personal or sensitive information to unauthorized parties with minor impact, minor financial loss, risk of civil or criminal violation which would not ordinary be subject to enforcement efforts, minor harm to individuals or the capability of the company to fulfill their mission is degraded. If the level of impact is moderate the effects of loss of confidentiality, integrity or availability are serious. Impacts can be significant damage to organizational assets, significant financial loss, serious short-term or limited long-term inconvenience,  serious short-term or limited long-term distress,  serious short-term or limited long-term damage to standing reputation, release of personal or sensitive information to unauthorized parties with moderate impact, risk of civil or criminal violations which may be subject to enforcement efforts, significant harm to individuals or significant degradation of mission fulfillment. The last level of potential impact is high, meaning that the effects can be severe or catastrophic. This means for example major damage to organizational assets, major financial loss, severe or serious long-term inconvenience, severe or serious long-term distress, severe or serious long-term damage to standing reputation, release of personal or sensitive information to unauthorized parties with high impact, risk of civil or criminal violation with special importance to enforcement programs, harm to individuals involving loss of life or serious life-threatening injuries and loss of capability to fulfill the mission [cf. (\cite{NIST:2004:FIOPS}, pp.6), (\cite{NIST:2017:DIG}, pp.21)].


The results of the risk assessment are needed to determine the minimum LOA. Once the risk assessment is complete the risk assessment impact profile can then be compared to the impact profiles associated with each assurance level. The table \ref{tab:maxImpacts} 'Maximum Potential Impacts for each Assurance Level' can help to determine the required assurance level by finding the lowest level whose impact profile meets or exceeds the potential impact for every category analyzed in the risk assessment [cf. (\cite{NIST:2017:DIG}, p.25)].

\begin{table}[h]
	\centering
	\begingroup
	\setlength{\tabcolsep}{10pt} % Default value: 6pt
	\renewcommand{\arraystretch}{1.5} % 
	\begin{tabular}{lccc}
		\hline
		\rowcolor[HTML]{656565} 
		{\color[HTML]{FFFFFF} }                                                                                                     & \multicolumn{3}{c}{\cellcolor[HTML]{656565}{\color[HTML]{FFFFFF} Assurance Level}}                  \\ \hline
		\multicolumn{1}{|c|}{\textbf{Impact Categories}}                                                                            & \multicolumn{1}{c|}{\textbf{1}} & \multicolumn{1}{c|}{\textbf{2}} & \multicolumn{1}{c|}{\textbf{3}} \\ \hline
		\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}Inconvenience, distress or damage to\\ standing or reputation\end{tabular}} & \multicolumn{1}{c|}{Low}        & \multicolumn{1}{c|}{Mod}        & \multicolumn{1}{c|}{High}       \\ \hline
		\multicolumn{1}{|l|}{Financial loss or agency liability}                                                                    & \multicolumn{1}{c|}{Low}        & \multicolumn{1}{c|}{Mod}        & \multicolumn{1}{c|}{High}       \\ \hline
		\multicolumn{1}{|l|}{Harm to agency programs or public intrests}                                                            & \multicolumn{1}{c|}{N/A}        & \multicolumn{1}{c|}{Low/Mod}    & \multicolumn{1}{c|}{High}       \\ \hline
		\multicolumn{1}{|l|}{Unauthorized release of sensitive information}                                                         & \multicolumn{1}{c|}{N/A}        & \multicolumn{1}{c|}{Low/Mod}    & \multicolumn{1}{c|}{High}       \\ \hline
		\multicolumn{1}{|l|}{Personal safty}                                                                                        & \multicolumn{1}{c|}{N/A}        & \multicolumn{1}{c|}{Low}        & \multicolumn{1}{c|}{Mod/High}   \\ \hline
		\multicolumn{1}{|l|}{Civil or criminal violation}                                                                           & \multicolumn{1}{c|}{N/A}        & \multicolumn{1}{c|}{Low/Mod}    & \multicolumn{1}{c|}{High}       \\ \hline
	\end{tabular}
	\endgroup
	\caption{Maximum Potential Impacts for Each Assurance Level (\cite{NIST:2017:DIG}, p.25)} \label{tab:maxImpacts}
\end{table}

When analyzing the risk, it should be considered that there could be more than one error and multiple parties could be involved in the process. Furthermore, the potential impacts description often include relative terms like 'minor' and 'serious' which meaning will depend on the context. Over time and with experience the meaning of these relative terms becomes more definite [cf. (\cite{NIST:2017:DIG}, p.26)].

One of the most useful documents is NIST's 'Guide for Conducting Security Risk assessment'. The guide follows activities related to NIST'S guide of 'Risk Management Framework' which can be either applied to new or legacy information systems. Typically a risk assessment is a very complex task that takes much time and many external sources to be representative, for example expert opinions. If put together correctly one should end up with a Risk Management Framework (RMF). An RMF provides a process that integrates security and risk management activities into the system development life cycle. The system can be applied to both new and legacy systems. \cite{NIST:2018:RMF} defines 6 Steps in this RMF. The steps include the categorization of the information system, selection of baseline security controls, implementation of security controls, assessment of the security controls, authorize information system operation based on the determination of risk and monitoring security controls. Many industrial standard risk assessment methods across a wide array of fields and industries are based on these guides.  In this practical part, an initial risk assessment is done which should provide a general insight on how to do a risk assessment. The guide to success of a real-life risk assessment is documentation, review, and improvement.  However, since a full RMF is out of scope, a scaled down version that is distinctive of digital identity risk management is conducted  [cf. (\cite{NIST:2018:RMF})].


To prepare for a risk assessment, it helps to identify the purpose, scope, assumptions, and constraints beforehand. The purpose of this risk assessment is to make authorization-related decisions and conducting an initial assessment to identify potential threats, internal and external vulnerabilities which impact the organizations. The scope addresses the 3 Tier -  information system level with a focal point on the risk assessment of a single sign-on federation system. Furthermore, the scope is defined by the result expected from the risk assessment. In this risk assessment, the result should be an authentication and authorization solution for a specific use case. The assessment result should usually be reevaluated after the initial draft. [cf. (\cite{NIST:2012:GCRA}, pp.24)].

Before starting with the risk assessment a risk model has to be chosen. The model can be translated into risk factors which then can be assessed; these risk factors consist of threat, vulnerability, impact, likelihood and predisposing conditions.  A threat is a circumstance with the potential to impact the organization. Threat events are caused by threat sources. Threat sources that should be considered in the model can address broad threat sources or particular threat sources. Potential threat sources can be adversarial like Insider, Outsider, Trusted Insider, Privileged Insider, Customer, or Competitor. A thread source can also be accidental like User, Privileged User/Administrator or structural like IT-Equipment (Storage, Communication, Processing), Environmental (Temperature/Humidity, Power Supply) or Natural (Fire, Bombing, Earthquake, Sunspots). These potential sources can then cause threat events which can be expressed very general or can also be very specific. Which threat are considered depend highly on the company. A company might choose to only consider previously observed events or all possible events. Examples of potential threat sources are cause integrity loss by injecting false but believable data into organizational information systems, obtain unauthorized access, obtain sensitive data/information from publicly accessible information systems, cause disclosure of critical and/or sensitive information by authorized users, conduct externally-based session hijacking, conduct simple Denial of Service (DoS) attack, craft phishing attacks and so on. The likelihood is a weighted risk factor based on the probability that a given threat is capable of exploring a given vulnerability. A vulnerability is an existing weakness in an information system, system security procedures, internal controls, or implementation that could be exploited by a threat source. Most vulnerabilities are caused by unimplemented or not correctly implemented security controls. Some recommended security controls are described in 'Recommended Security Controls for Federal Information Systems and Organizations'. The implementation of appropriate security controls is an important task that can have a major impact on the operations and assets of a company. Security controls are used to protect the confidentiality, integrity and availability of a system and it's information. Examples are Identifier Management, Authenticator Management or Authenticator Feedback. Closely related to vulnerabilities is a predisposed condition which is a condition within a company which affects the likelihood that threat events once initiated, result in adverse impact on the organization like the involvement of PII. The consequences that a successfully exploited vulnerability by a threat source has, is then described by the impact  [cf. (\cite{NIST:2012:GCRA}, pp17, pp35, pp70), (\cite{NIST:2017:SecurityNPrivacyControls})].

Last but not least before stating a risk assessment based on a risk model, an analytic approach and an assessment approach should be considered. The assessment approach can be quantitative, qualitative or semi-quantitative each of the factors including three assessment scales with different corresponding representations. A quantitative assessment is based on the use of numbers whereas the qualitative assessment typically uses nonnumerical categories or levels like very low, low, moderate, high, very high. Finally, semi-quantitative assessment is a combination of a quantitative and a qualitative assessment using bins, scales or representative numbers. For low impact information systems, the qualitative values are used while for moderate-and high-impact systems; the most granular semi-quantitative values are used. The analysis approach is either threat-oriented, asset/impact-oriented or vulnerability-oriented. With the analysis approach the starting point of the risk assessment can be chosen. The risk assessment starting point can either be based on existing vulnerabilities or assets in the company or possible threats  [cf. (\cite{NIST:2012:GCRA}, pp17)].

Based on this knowledge a few examples considering the use case above where conducted. Based on the remarks above and on an example from \cite{Hudson:2015:SecurityRisk}  the following steps were followed  'Identify Threat', 'Identify Vulnerability', 'Current Controls', 'Likelihood of Impact', 'Effect of Impact' and 'Risk Determination'. Since it is an initial risk assessment, there are no 'Current Controls'. Therefore, this step is left out. The 'Likelihood of Impact' can be assigned a value from low to high whereas high means it is very likely that a vulnerability is exploited by a threat. The lowest value of 'Likelihood of Impact' is 0.1, and the highest is 1. The 'Effect of the Impact' is assigned a value between 0 to 100. A low 'Effect of Impact' means that the consequences are low and high Effect of Impact means that the consequences are severe. To determine to the overall risk of a threat, the 'Likelihood' is multiplied with the 'Impact' (Likelihood x Impact) resulting in the risk levels:

\begin{itemize}
	\item Low =     0-33
	\item Medium = 34-66
	\item High =   67-100
\end{itemize}

Since this analysis is about identity proofing, authentication and federation errors a few threats were chosen to be analyzed with the risk assessment. It should be noted that this does not represent a complete risk assessment since there are more factors to be considered. The risk analysis sees outsiders who want to harm the company and users and identifies them as potential threat sources. 

\paragraph{Identity Proofing Risk 1}

\begin{enumerate}
	\item Technical Threat: An attacker successfully proofs as someone else
	\item Vulnerability: Phishing over unencrypted network communication
	\item Likelihood: 0.5
	\item Impact: 80 (Inconvenience, distress)
	\item \textbf{Risk Determination}: 0.5 x 80 = 40 (Medium Risk) 
\end{enumerate}

\paragraph{Identity Proofing Risk 2}
\begin{enumerate}
	\item Technical Threat: Collecting and securely storing more information about a person that is required to successfully provide the digital service
	\item Vulnerability: Identity Provider is collecting more information than needed from the user on login. Users might not trust the application or not use it
	\item Likelihood: 0.8
	\item Impact: 30  (Unauthorized release of sensitive information)
	\item \textbf{Risk Determination} : 0.8 x 30 = 24 (Low Risk)
\end{enumerate}


\paragraph{Authentication Risk 1}
\begin{enumerate}
	\item Technical Threat: False claimant using credentials which is not rightfully theirs
	\item Vulnerability: User keeps credentials at an insecure place
	\item Likelihood: 0.9
	\item Impact: 60 (Inconvenience, distress and Unauthorized release of sensitive information )
	\item \textbf{Risk Determination}: 0.9 x 70 = 64 (Medium Risk) 
\end{enumerate}

\paragraph{Authentication Risk 2}
\begin{enumerate}
	\item Technical Threat: Account is compromised and user is using same identifier and authenticator for other accounts
	\item Vulnerability: User uses same credentials for multiply accounts
	\item Likelihood: 0.8
	\item Impact: 70 (Inconvenience, distress and unauthorized release of sensitive information)
	\item \textbf{Risk Determination}: 0.8 x 70 = 56 (Medium Risk)
\end{enumerate}

\paragraph{Federation Risk 1 }
\begin{enumerate}
	\item Technical Threat: An identity assertion is compromised
	\item Vulnerability: Transaction involving third party not over protected channel
	\item Likelihood: 0.6
	\item Impact: 40 (Inconvenience, distress)
	\item \textbf{Risk Determination}: 0.6 x 40 = 24 (Low Risk)
\end{enumerate}

\paragraph{Federation Risk 2 }
\begin{enumerate}
	\item Technical Threat: Identity Server is unavailable
	\item Vulnerability: Environmental influences 
	\item Likelihood: 0.1
	\item Impact: 100 (Inconvenience, distress and financial loss)
	\item \textbf{Risk Determination}: 0.1 x 100 = 10 (Low Risk)
\end{enumerate}


An initial risk assessment can take a long time but once conducted the following risk assessments will be much quicker. Modern digital services often combine identity proofing, authentication and federation requirements in one single bundle. It is better to look at each of this components separately to delivery the best identity service. The outcome of the separate component can then be compared to categorize of the table \ref{tab:maxImpacts} Maximum Potential Impacts on Each Assurance Level and which assurance Level is associated with the risk outcome. Therefore the highest risk is taken and associated with the appropriate assurance level. After the initial risk assessment with just a view threats that were analyzed the associated risk level for identity proofing would be 2, for authentication risk, it would be 2, and for federated risk, the assurance level would be 1 [cf. (\cite{NIST:2017:DIG}), (\cite{NIST:2018:RMF}), (\cite{Hudson:2015:SecurityRisk})].

To make it easier to chose an initial assurance level the 'Digital Identity Guidelines' form \cite{NIST:2017:DIG} provide an additional assessment on how to choose a appropriate assurance level. Therefore three flowcharts are provided that need to be followed and will then point to an appropriate assurance level. The flow through the cart is represented with the color red. The first flow chart is \ref{fig:ialflow} Identity Assurance Flow Chart. Choosing a Identity Assurance Level however does not mean that the identity proofing has to be done by the party who does the assessment - it can also be federate. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{images/ial_flow}
	\caption{Identity Proofing Assurance Flow Chart (\cite{NIST:2017:DIG}, p 27)}
	\label{fig:ialflow}
\end{figure}

In \ref{fig:ialflow} Identity Proofing Assurance Flow Chart the first question is if PII is needed to provide the service. In our use case, probably sensitive company information is provided therefor yes - personal information is needed. Some of the attributes that are provided have to be validated and can not be self-asserted attributes only. The next step covers potential impacts of identity proofing. The two risk that is considered here are the most primary identity proofing failures from the view of the user and the company: accepting a falsified identity as true and collecting more information as needed. Question 5 focuses on whether the service should be able to access full attribute values. That does not mean that all attributes have to be delivered in claims, but it should be considered. If yes was picked at the question the service is an excellent candidate for a federated infrastructure [cf. (\cite{NIST:2017:DIG}, pp28)]. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{images/aal_flow}
	\caption{Authentication Assurance Flow Chart (\cite{NIST:2017:DIG}, p 30)}
	\label{fig:aalflow}
\end{figure}

The next flowchart is \ref{fig:ialflow} Authentication Assurance Flow Chart which should help choose a company deciding on the authenticators necessary for the service. First, the risks of letting an unauthorized user access information from the perspective of the organization and the user are considered. In this use case company, sensitive information of the customer are endangered an e-mail filtering report however does not have devastating impacts on the customers business. Therefore the assessment ends with the AAL2 [cf. (\cite{NIST:2017:DIG}, pp30)].  

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{images/fal_flow}
	\caption{Federation Assurance Flow Chart (\cite{NIST:2017:DIG}, p 32)}
	\label{fig:falflow}
\end{figure}

Since it was evaluated in the \ref{fig:ialflow} Identity Proofing Flow Chart that the service is recommended for a federated solution the last flowchart is the \ref{fig:falflow} Federated Assurance Flow Chart. The first thing that is considered is the impact of an unauthorized user compromising an assertion from the organization and the subscriber view. For example assertion replay to impersonate a valid user or leakage of assertion information through the browser. Therefore the assurance level FAL2 is chosen [cf. (\cite{NIST:2017:DIG}, pp32)]. 


This initial assertion should give a general direction in which security controls should be in place passed on the different LOA. The risk assessment helps to balance out security and usability, to give the user the best experience. After the first realization of the project, the risk assessment should be done again and refined including the current security controls which are in place.
 



\section{Solution}
The \cite{Sakimura:2014:OpenIDConnect} explains that modern applications have different requirements than their predecessors, due to new distributed architectures that allow enterprises to be more flexible. Cloud or microservice architectures require different interactions between applications.The below figure \ref{fig:architecture-identityserver} shows the most common interactions for modern applications.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{images/architecture-identityserver}
	\caption[Architecture IdentityServer4]{Architecture IdentityServer4 (\cite{Brock:2018:ID4}}
	\caption{Architecture IdentityServer4 (\cite{Brock:2018:ID4}}
	\label{fig:architecture-identityserver}
\end{figure}



For example, a browser might call a Web App, and a Web App calls a Web API or perhaps a Native App calls a Web API, which is calling another Web API. Each application has to implement security functions to maintain a secure flow throughout these interactions. Implementing this security features for each involved application leads to a lot of duplicated code and inconsistencies. A different approach to implement security throughout these flows is using a token service. A token service brings the benefit of being able to encapsulate these security functions. Security functions can be updated and hosted at a single point which prevents duplicated functions across applications and security flaws. The advantages of a token service or token based application are also outlined in the section \ref{tokenBasedAuthentication} Token-based Authentication. Furthermore the chapter \ref{tokenBasedAuthentication} hold examples of JSON Tokens and how they are asserted. The concept of JSON Tokens is very important in token-based authentication systems and ensures confidentiality and integrity [cf. (\cite{Sakimura:2014:OpenIDConnect})].


Based on the chapter \ref{riskassessment} Risk Assessment the architecture of the authentication system for the use case described in chapter \ref{usecase} Use Case is chosen. The LOA for Identity Proofing should be according to the risk assessment the second one - other LOA are coverd in chapter \ref{identityProofing}. The second level of assurance for identity proofing suggests that no real-world existence of the claimed identity has to be present. The other identity proofing assurance levels can be looked up in chapter \ref{identityProofing} Identity Proofing. The presentation of the real-existence can be either remote or physical. Furthermore the figure \ref{fig:ialflow} suggest that since a identity should be resolved uniquely in our use case and it is ok to accept references therefore a federation solution is recommended. In order to successfully proof an identity the client or user has to provide valid credentials to authenticate at the service. The  authentication assurance level is also analyzed in the chapter \ref{riskassessment} Risk Assessment. According to this initial risk assessment the level of assurance should be two other LOA are described in chapter \ref{authentication}. The second level of authentication assurance suggests to use at least two distinct authentication factors and the use of strong cryptographic techniques. However since this was the first risk assessment conducted, the first level for authentication will be used because two distinct authentication factors would be normally used for really sensitive personal data like in a bank app. The first level of assurance for authentication suggest the use of just one authentication factor. Furthermore, since the first identity proofing flow chart also suggested to use federation, the according federation assurance level based on the risk assessment should be the first. The first level of assurance states to use a bearer assertion signed with approved cryptography by an IdP like OpenID Connect Basic Client profile. Therefor the solution will use an token service which login functionality is  accepting one distinct authentication factor and asserts the user with bearer tokens. 


The languages chosen for the example application are C\# and Angular 2. The solution is created with a very useful ASP.NET framework called Identity Server4. Identity Server4 uses the specifics of OpenID Connect and OAuth 2.0 to enable authentication and authorization related features. Features include authentication as a Service, which provides a centralized login logic for all applications, Single sign-on, Access Control for APIs and Federation Gateway. The Identity Server 4 will be used as a Token Server in the practical part [cf. (\cite{Brock:2018:ID4})]

The project illustrating the use of Identity Server and the benefits of OpenID Connect an OAuth is a Visual Studio Project mostly written in C\# and Typescript. The project example for Identity Server includes four different projects:

\begin{itemize}
	\item Identity Server - The Identity Server is a ASP.NET Core Project with basic implementation of an Identity Server which serves as a Token Server. 
	\item ProjectApiNetCore - This application is a ASP.NET Core 2.0 API Application with basic API that returns the users claims if he is authenticated.
	\item Angular Client - The Angular Client is a ASP.NET Core MVC Angular Project used as a client that can be accessed by an End-User who can authenticate with the Identity Server and requests protected resources of the API ProjectApiNetCore.This project uses the Implicit Code Flow. 
	\item MVC Client - The MVC Client is a ASP.NET Core MVC Project used as a Client that can be accessed by an End-User and can authenticate with the Identity Server and requests protected resources of the API ProjectApiNetCore. This project uses the Hybrid Code Flow. 
\end{itemize}



\paragraph{Identity Server}

This project is using the IdentityServer4 library by Brock Allen and Dominick Baier. The Project works as a Token Server which means that the Identity Server Project is responsible for the authentication of the user, managing the identities and provide and approve tokens. Furthermore, the Identity Server implements different Authentication Flows.


\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/middlewareIdentityServer}
	\caption{IdentityServer Middleware}
	\label{fig:middlewareidentityserver}
\end{figure}
 

IdentityServer4 adds endpoints of OAuth 2.0 and OpenID Connect to an arbitrary ASP.NET Core application as shown in \ref{fig:middlewareidentityserver}. The identity server can be as complex as the developer wants but \cite{Brock:2018:ID4} recommends to keep the attack surface as small as possible by just including authentication related UI only [cf. (\cite{Brock:2018:ID4})]. 


For the basic setup, the Identity Server has to be added to the StartUp class and to ensure a secure communication a certificate is created to sign the request. For the basic setup, Identity Server provides us with DeveloperSigningCredentials which provides a dummy certificate. In this example application, a real certificate is included. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{images/self-signed-certicate}
	\caption{Self signed Certicate with Powershell}
	\label{fig:self-signed-certicate}
\end{figure}

The certificate used in this application was created with Powershell as shown in \ref{fig:self-signed-certicate}. The algorithm used in this certificate is RSA. Depending on the algorithm that is used in the certificate a similar hashing algorithm has to be used for the Client Secret.


The API Resources include the available APIs that can be called and included in the scope of a request. The Identity Resources are Resources that can be included in the returning id\_token. The clients are the available clients that can be configured and can use the Identity Server. Those client Configurations indicate which Authorization Flow is used and how to retrieve id\_token, access\_token, and a possible refreh\_token. For simplifying reasons, Identity Server provides an in Memory User Storage which can be used for testing reasons. Other ways to define users are via .NET Core Identity or IdentityServer4 EntityFramework. For the purpose of this implementation this test users where included in the Identity Server application:
\begin{enumerate}
	\item User1:
	\begin{itemize}
		\item  Username: bob
		\item  Password: bob
	\end{itemize} 
	\item User2:
	\begin{itemize}
		\item  Username: alice
		\item  Password: alice
	\end{itemize} 
\end{enumerate}

After the basic setup of the Identity Server, it can be examined if the Identity Server is running correctly by calling the discovery document. The discovery document can be used by the Clients and APIs to retrieve necessary configuration data. The Identity Server has to run at local port 5000 and the navigation path for the browser is:
\url{http://localhost:5000/.well-known/openid-configuration}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/openid-discovery-document}
	\caption{OpenID Discovery Document}
	\label{fig:openid-discovery-document}
\end{figure}
The discovery document is located at a well-known location and is containing key-value pairs as a JSON structure. The key-value pairs in the discovery document represent multiple endpoints that are used to authenticate a user including URIs of the authorization, token, userinfo, and public-keys endpoint. The use of a discovery document brings more flexibility to the protocol. The application should have the discovery URL hard-coded in the application according to (\cite{Google:2018:IdentityPlatform}) the discovery document URL can then be used to fetch endpoints from the document and use them to send an authentication request for example [cf. (\cite{Google:2018:IdentityPlatform})].

The metadata that is seen in \ref{fig:openid-discovery-document} OpenID discovery document is a mixture of required elements with some recommended ones that are implemented by the Identity Server. The required elements are issuer, authorization\_endpoint, token\_endpoint, jwks\_uri, response\_types\_supported, subject\_types\_supported and id\_token\_signing\_alg\_supported. The issuer, in this case, is this Identity Servers address. The authorization\_endpoint is the URL OAuth 2.0 Authorization Endpoint. The user is redirected to the authorization server's authorization endpoint for authentication and authorization. The authentication request that is sent to the authorization server can have different request parameters. These request parameters are defined by OAuth 2.0 and additional request parameters defined by OpenID Connect. The token\_endpoint is the URL of the OAuth 2.0 Token Endpoint. The RP can request access or optionally refresh tokens from the token endpoint. The user\_endpoint can be used to request additional information concerning the user. The response\_types\_supported is a important information about what kind of response is supported and ultimately what kind of authentication flow can be used based on that information described in chapter \ref{chap:authenticationandauthorization} in Single-Sign on Federate Systems. The subject\_types\_supported is a list of subject identifier types. Moreover, last but not least id\_token\_signing\_alg\_supported is used to find out which JWS is signing algorithm is used to encode the ID token and get the claims of the JWT. The algorithm RS256 must be included [cf. (\cite{Sakimura:OIDCC}, (\cite{Sakimura:OIDCD}))].. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{images/jwkDiscovoryDocument}
	\caption{JWKS Endpint}
	\label{fig:jwkdiscovorydocument}
\end{figure}

The jwks\_endpoint is worth a closer look. JWKS SET is published to the JWKS endpoint. The keys shown in (\ref{fig:jwkdiscovorydocument} JWKS Endpoint) can be rolled over by periodically adding new keys to the JWK Set. This also indicates if the cryptographic algorithms are configured correctly. For example the message is using the kid of signing key in the JOSE Header to indicate which key has to be used to validate the signature. The algorithm used by the signing party has to be supported by the recipient and can be either an Asymmetric Signature or a Symmetric Signature. 
When using RSA or ECDSA signatures, the alg Header Parameter has to be set to the correct algorithm, and the private key used to sign must be associated with the public key published by the sender. When using MAC-based signatures, the alg Header Parameter has to be set to the correct algorithm, and the MAC key is the octets of the UTF-8 representation of the client\_secret. MAC-based signatures cannot be used by public Clients because they cannot keep secrets.  All metadata types are listed in the specification of OpenID Discovery Document from \cite{Sakimura:OIDCD} [cf. (\cite{Sakimura:OIDCC}, (\cite{Sakimura:OIDCD}))]. 

After calling the OpenID discovery document and the JWKS endpoint, one can be ensured that the basic setup of the IdentityServer works. After that a resource that is worth beeing protected by the Identity Server has to be created. 

\paragraph{ProjectApiNetCore}

This ProcjectApiNetcore is an ASP.NET Core application. This application represents the Resource Server and serves the Protected Resources. In this particular example, the API provides a list of Products the user bought from the company and the possibility to download the report that gives information about the current state of the product. The example API provides dummy data for the particular request. For easy testing of the API and designing the API, swagger.io is used. Furthermore, swagger.io (\url{https://swagger.io/}) gives a nice developer experience with an interactive API documentation. In addition, it is possible to generate code out of the swagger documentation for different programming languages with tools like NSwag (\url{https://github.com/RSuter/NSwag}).

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{images/apis}
	\caption{API documentation with Swagger}
	\label{fig:apis}
\end{figure}

All of the routes shown in \ref{fig:apis} API documentation with Swagger, are secured with the help of the IdentityServer4.AccessTokenValidation NuGet package. Each Controller gets an Authorize annotation. 
To configure the right authentication method, ASP.NET Core 2.0 offers the possibility to add the authentication to the pipeline with Dependency Injection via the method Configure Services in the Startup.class.
In the StartUp class of the API Project the AddAuthentication with the Value "JwtBearerDefaults.AuthenticationScheme" makes "Bearer" the default authentication scheme. With the AddIdentityServerAuthentication it is defined which Token server can be used to validate the incoming token and make sure that this token is from a trusted issuer. It adds the Identity Server access token validation handler into DI and also it is checked if the token is valid to be used with this API (aka scope). Adding UseAuthentication to the Configure method int the Startup class adds the authentication middleware to the pipeline so authentication will be performed automatically on every call into the host.  Multiple authentication schemes can be used. A list of authentication schemes is then passed to the Authorize attribute separated with a comma. The default scheme results in the HttpContext.User property is set to that identity. After adding the Authentication logic to the API Project, the resources should be protected now. To check if the resources are protected the Swagger documentation can be used. Therefore navigate to \url{http://localhost:5001/swagger/v1/swagger.json} and try out one of the methods shown in (\ref{fig:apis}) API Documentation with Swagger. This should result in a 401 Unauthorized HTTP response code.


\paragraph{Client}The client represents the UI of the 'Security Assessment Portal' with the initial E-Mail-Filtering functionality. The project is an Angular Solution that follows the Implicit Code Flow described in chapter \ref{OAuthAndOpenID}. The Implicit Code Flow is chosen over the other Code Flows based on the type of application, level of trust and the user experience that should be provided. The first decision is based on rather the machine that hosts the application is the resource owner as well. If this is the case no end-user authorization is needed. In this use-case the resource owner is accessible over the API we provided which is hosted on a different server. If the application is a regular web app the Authorization Code Flow would be recommended. However since the client we are hosting is a Angular SPA app the Implicit Code Flow should be used. The application directly receives an access token and no additional round trips are needed to exchange an received authorization code. The implicit code flow does not return a refresh token because it can not be kept secret but there is the possibility of a silent authentication. The silent authentication is initiated with a request to the authentication request with the parameter 'promt=none'. On success the client is redirected to the redirect\_uri with an successful authentication response. If the user is not already logged on the client is redirected to the redirect\_uri wit an error response [cf. \cite{OAuth:2018:Flow}].  


For the Implicit Code Flow, the Identity Server has to define a Client that Allows the Grant Type Implicit as shown in \ref{fig:implicitcodeflow} Implicit Code Flow- Identity Server Configuration. The defined Client can be identified with the ClientId. This particular Client also requests the explicit consent of the Client for the requested Scopes. In this case, the Client is allowed to request the well known Scopes OpenId and Profile. In order to receive an id\_token and therefore configure OpenId Connect the scope OpenId has to be requested. The Profile scope gives general information about the user. Also, an API scope is added for ‘securityPortalApi’, which represents the API Project holding the Resources. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/implicit_code_flow}
	\caption{Implicit Code Flow - Identity Server Configuration}
	\label{fig:implicitcodeflow}
\end{figure}


AllowAccessTokensViaBrowser makes sure that the access\_token can be directly returned to the Browser after the client authenticates itself. AllowCorsOrignins allows the given resource to make Cross-Origin-Requests to the Identity Server. Cross-Origin-Request is a request that is made from another domain outside the domain from which the first resource was served. Furthermore, the RedirectUris have to be present, in order for the Identity Server to know where to return after the login attempt was successful. 


In the Angular Solution, a Service to handle authentication was created. The service handles requests to the API which is hosting the Protected Resources. The Angular Solution uses the ‘oidc-client’ library that is suggested by the Identity Server framework to handle authentication requests. To call the Identity Server the following setting shown in \ref{fig:implicitcodeflowangular} Implicit Code Flow - Angular.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/implicit_code_flow_angular}
	\caption{Implicit Code Flow - Angular}
	\label{fig:implicitcodeflowangular}
\end{figure}


The client\_id in the Angular Solution has to be the same as the ClientId configured in the Identity Server Project. The same is true for the redirect\_uri and post\_logout\_redirect\_uri. Otherwise, the request would result in an error. For example, if a scope is requested which does not exist according to the Identity Server, an invalid scope exception is thrown. Furthermore, the response\_type has to be according to the used Authorization Flow in the in IdentityServer's client configuration. In the Identity Server Solution, the  Implicit Code Flow was configured, therefore "id\_token token" was defined. The response of these response types will include an access token, an access token type and an id\_token.  

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/secure_page_requires_login}
	\caption{Secure Page Login}
	\label{fig:securepagerequireslogin}
\end{figure}

For the Client to receive an id\_token and in this example an access\_token from the Authorization Server (Identity Server Project), the client has to prepare an Authentication Request and send it to the Authorization Server. The Angular has two possible ways to trigger the login with the Identity Server. In the navigation on the left-hand side there is a Homepage that can be accessed by everyone, then there is a Secure Page that just can be accessed by logged in users and the Login Page, which automatically triggers a request to the Authorization Server.



The \ref{fig:securepagerequireslogin} Secure Page Login, shows the Menu of the application. If the user tries to access the Secure Page without being logged he is redirected to the "Login is required" Page. In order to access the secure area, the End-User has to authenticate with the Authorization Server.
To authenticate with the Authorization Server the user has to press the Login button. After the Login button is pressed, the End-User is redirected to the Authorization Server Login Page. The design of this screen can be adjusted in the Identity Server Project. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/login_identity_server}
	\caption{Login Mask Identity Server}
	\label{fig:loginidentityserver}
\end{figure}


The figure \ref{fig:loginidentityserver} Login Mask Identity server shows the form where the End-User can log in with the End-User’s credentials. In the Identity Server Project, two Test-User are registered. Therefore either as Alice or Bob can currently log in to the application and view the secured Page. 
The Authorization Server can also request consent from the User for the requested Claims. In the Identity Server Project, it is configured that the consent of the End-User is required. In consequence of this configuration, the user is prompted an additional screen. This screen is shown in \ref{fig:consentscreen} Consent Screen, would not appear if the consent was not required by the identity server. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/consent_screen}
	\caption{Consent Screen}
	\label{fig:consentscreen}
\end{figure}


The Angular Application is requesting consent for the requested scopes openId, profile and securityPortalApi. The openId Scope is required because otherwise, we would not be able to receive an id\_token. User Profile gives additional information about the User, and the  Security Assessment Portal API is a custom API that was added to the scope and allows the user to make requests to this API and the protected resources. 


After the End-User has given its consent, the End-User gets redirected back to the Client with an id\_token and an access\_token. The id\_token can be validated, and an End-User’s Subject Identifier is retrieved.


\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{images/claims}
	\caption{Claims}
	\label{fig:claims}
\end{figure}


It the authentication with the Authorization Server was successful the End-User is now authenticated. As an authenticated user the End-User can now also access the Secure Page. With access\_token the received access token calls to the custom API Project can be executed. For example, the claims of the user that are correlating to the scopes can be received and put in a useful context as seen in figure \ref{fig:claims}.

This complete example could be a possible implementation of the authentication for the described use case in section \ref{usecase}. Now it would also be possible for an external user (customers) to access the application without a domain account. If customers also choose to use other products of the companies, no new account is required because the same identity server can be used. The personal data of the customers stays in the company and is not given to any third party. With the use of token-based authentication, it is easy to manage the session of end-users, and the user can stay logged in the application (single-sign-on). The use of bear tokens gives appropriate security and the implicit flow used to deliver the token makes it very light-weighted for single page application. The separated API is also convenient because it might be used for multiple purposes.

\chapterend
